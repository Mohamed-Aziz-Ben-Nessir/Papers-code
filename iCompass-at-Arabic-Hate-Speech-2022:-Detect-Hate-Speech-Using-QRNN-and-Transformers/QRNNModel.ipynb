{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JAY_Rt33I8DO",
        "outputId": "4710209b-0182-42f3-effa-796d8da590b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.19.0)\n",
            "Requirement already satisfied: tensorflow-addons in /usr/local/lib/python3.7/dist-packages (0.16.1)\n",
            "Requirement already satisfied: focal_loss in /usr/local/lib/python3.7/dist-packages (0.0.7)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.6.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.8)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons) (2.7.1)\n",
            "Requirement already satisfied: tensorflow>=2.2 in /usr/local/lib/python3.7/dist-packages (from focal_loss) (2.8.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal_loss) (1.1.2)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal_loss) (3.17.3)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal_loss) (2.8.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal_loss) (3.3.0)\n",
            "Requirement already satisfied: tf-estimator-nightly==2.8.0.dev2021122109 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal_loss) (2.8.0.dev2021122109)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal_loss) (1.1.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal_loss) (0.2.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal_loss) (1.14.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal_loss) (3.1.0)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal_loss) (2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal_loss) (1.44.0)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal_loss) (2.8.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal_loss) (1.0.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal_loss) (1.6.3)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal_loss) (0.25.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal_loss) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal_loss) (57.4.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal_loss) (14.0.1)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal_loss) (0.5.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow>=2.2->focal_loss) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow>=2.2->focal_loss) (1.5.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.2->focal_loss) (3.3.6)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.2->focal_loss) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.2->focal_loss) (0.6.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.2->focal_loss) (1.0.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.2->focal_loss) (1.35.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.2->focal_loss) (1.8.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow>=2.2->focal_loss) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow>=2.2->focal_loss) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow>=2.2->focal_loss) (4.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow>=2.2->focal_loss) (1.3.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow>=2.2->focal_loss) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow>=2.2->focal_loss) (3.2.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers tensorflow-addons focal_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-40rd7lvQNV",
        "outputId": "c45439de-a432-4fe3-ac82-199de33bae99",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.7.243.218:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.7.243.218:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.7.243.218:8470\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.7.243.218:8470\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n",
            "WARNING:absl:`tf.distribute.experimental.TPUStrategy` is deprecated, please use  the non experimental symbol `tf.distribute.TPUStrategy` instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, TFAutoModel, AutoConfig\n",
        "import re\n",
        "import io\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import f1_score, accuracy_score,precision_score,recall_score\n",
        "from zipfile import ZipFile\n",
        "from IPython.display import FileLink \n",
        "import tensorflow as tf\n",
        "\n",
        "np.random.seed(45)\n",
        "tf.random.set_seed(45)\n",
        "tpu_strategy = tf.distribute.experimental.TPUStrategy(tf.distribute.cluster_resolver.TPUClusterResolver.connect())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oYyts0EqvQNW"
      },
      "outputs": [],
      "source": [
        "train_data=pd.read_csv(\"/content/train.csv\")\n",
        "valid_data=pd.read_csv(\"/content/dev.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b-kuvxMzldvQ"
      },
      "outputs": [],
      "source": [
        "# OFF=train_data.loc[(train_data[\"OFF_label\"]==1)&(train_data[\"HS_label\"]==0)].sample(1100,)\n",
        "# NORM=train_data.loc[train_data[\"OFF_label\"]==0].sample(1100)\n",
        "# HS=train_data.loc[train_data[\"HS_label\"]!=0]\n",
        "# train_data=OFF.append(NORM)\n",
        "# train_data=train_data.append(HS)\n",
        "# # train_data=train_data.append(HS)\n",
        "# # train_data=train_data.append(HS)\n",
        "# train_data=train_data.sample(frac=1).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uuP2kPYQvQNW"
      },
      "outputs": [],
      "source": [
        "def encode_labels(data):\n",
        "    encoded_OFF=tf.convert_to_tensor(data[\"OFF_label\"].astype(\"int32\"))\n",
        "    #encoded_HS=tf.keras.utils.to_categorical(data[\"HS_label\"],num_classes=7)\n",
        "    encoded_HS=tf.convert_to_tensor(data[\"HS_label\"].astype(\"int32\"))\n",
        "    text=list(data[\"tweet_text\"].astype(\"str\"))\n",
        "    return text,encoded_OFF,encoded_HS\n",
        "\n",
        "train_text,train_OFF,train_HS=encode_labels(train_data)\n",
        "valid_text,valid_OFF,valid_HS=encode_labels(valid_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "416Gqk7NvQNX"
      },
      "outputs": [],
      "source": [
        "def OFF_not_HS_feature_gen(encoded_OFF,encoded_HS):\n",
        "    OFF_not_HS=[]\n",
        "    for x,y in zip(encoded_OFF,encoded_HS):\n",
        "        OFF_not_HS.append(int(x==1 and y==0))\n",
        "    return tf.convert_to_tensor(OFF_not_HS)\n",
        "\n",
        "def Binary_HS_feature_gen(encoded_HS):\n",
        "    HS_bn=[]\n",
        "    for x in encoded_HS:\n",
        "        HS_bn.append(x!=0)\n",
        "    return tf.convert_to_tensor(HS_bn)\n",
        "\n",
        "train_OFF_not_HS=OFF_not_HS_feature_gen(train_OFF,train_data[\"HS_label\"])\n",
        "train_HS_bn=Binary_HS_feature_gen(train_data[\"HS_label\"])\n",
        "valid_OFF_not_HS=OFF_not_HS_feature_gen(valid_OFF,valid_data[\"HS_label\"])\n",
        "valid_HS_bn=Binary_HS_feature_gen(valid_data[\"HS_label\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NbwcCliovQNX"
      },
      "outputs": [],
      "source": [
        "def tokenize(sentences):\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\"UBC-NLP/MARBERTv2\")\n",
        "    input_ids, input_masks = [],[]\n",
        "    for sentence in sentences:\n",
        "        inputs = tokenizer.encode_plus(sentence, add_special_tokens=True,max_length=256,truncation=True, padding='max_length',return_attention_mask=True, return_token_type_ids=True)\n",
        "        input_ids.append(inputs['input_ids'])\n",
        "        input_masks.append(inputs['attention_mask'])\n",
        "    return np.asarray(input_ids, dtype='int32'),np.asarray(input_masks, dtype='int32')\n",
        "\n",
        "train_input_ids,train_input_masks=tokenize(train_text)\n",
        "valid_input_ids,valid_input_masks=tokenize(valid_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1xcWQK0kvQNX"
      },
      "outputs": [],
      "source": [
        "def report_gen(predictions,labels):\n",
        "    report={\n",
        "    \"F1_macro\":f1_score(predictions,labels,average=\"macro\"),\n",
        "    \"Accuracy\":accuracy_score(predictions,labels),\n",
        "    \"Precision_macro\":precision_score(predictions,labels,average=\"macro\"),\n",
        "    \"Recall_macro\":recall_score(predictions,labels,average=\"macro\")\n",
        "    }\n",
        "    return report\n",
        "\n",
        "def eval_taskA(predictions_OFF,labels_OFF,return_predictions=False):\n",
        "    predictions_OFF=[int(i>0.95) for i in predictions_OFF]\n",
        "    return predictions_OFF if return_predictions else report_gen(predictions_OFF,labels_OFF)\n",
        "\n",
        "def eval_taskB(predictions_HS,labels_HS_bn,return_predictions=False):\n",
        "    predictions_HS_bn=[]\n",
        "    for pred in predictions_HS:\n",
        "        pred=list(pred)\n",
        "        max_value = max(pred)\n",
        "        max_index = pred.index(max_value)\n",
        "        predictions_HS_bn.append(max_index!=0)\n",
        "    return predictions_HS_bn if return_predictions else report_gen(predictions_HS_bn,labels_HS_bn)\n",
        "\n",
        "\n",
        "def eval_taskC(predictions_HS,labels_HS,return_predictions=False):\n",
        "    predictions_HS=tf.argmax(predictions_HS,axis=1)\n",
        "    return predictions_HS if return_predictions else report_gen(predictions_HS,labels_HS)\n",
        "\n",
        "def eval_taskD(predictions_OFF_not_HS,labels_OFF_not_HS):\n",
        "    predictions_OFF_not_HS=[int(i>0.95) for i in predictions_OFF_not_HS]\n",
        "    return report_gen(predictions_OFF_not_HS,labels_OFF_not_HS)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1-rv_jFccOdb"
      },
      "outputs": [],
      "source": [
        "from keras import backend as K\n",
        "from keras import activations, initializers, regularizers, constraints\n",
        "from keras.layers import Layer, InputSpec\n",
        "from keras.utils.conv_utils import conv_output_length\n",
        "\n",
        "def _dropout(x, level, noise_shape=None, seed=None):\n",
        "    x = K.dropout(x, level, noise_shape, seed)\n",
        "    x *= (1. - level) # compensate for the scaling by the dropout\n",
        "    return x\n",
        "\n",
        "\n",
        "class QRNN(Layer):\n",
        "    '''Quasi RNN\n",
        "    # Arguments\n",
        "        units: dimension of the internal projections and the final output.\n",
        "    # References\n",
        "        - [Quasi-recurrent Neural Networks](http://arxiv.org/abs/1611.01576)\n",
        "    '''\n",
        "    def __init__(self, units, window_size=2, stride=1,\n",
        "                 return_sequences=False, go_backwards=False, \n",
        "                 stateful=False, unroll=False, activation='tanh',\n",
        "                 kernel_initializer='uniform', bias_initializer='zero',\n",
        "                 kernel_regularizer=None, bias_regularizer=None,\n",
        "                 activity_regularizer=None,\n",
        "                 kernel_constraint=None, bias_constraint=None, \n",
        "                 dropout=0, use_bias=True, input_dim=None, input_length=None,\n",
        "                 **kwargs):\n",
        "        self.return_sequences = return_sequences\n",
        "        self.go_backwards = go_backwards\n",
        "        self.stateful = stateful\n",
        "        self.unroll = unroll\n",
        "\n",
        "        self.units = units \n",
        "        self.window_size = window_size\n",
        "        self.strides = (stride, 1)\n",
        "\n",
        "        self.use_bias = use_bias\n",
        "        self.activation = activations.get(activation)\n",
        "        self.kernel_initializer = initializers.get(kernel_initializer)\n",
        "        self.bias_initializer = initializers.get(bias_initializer)\n",
        "        self.kernel_regularizer = regularizers.get(kernel_regularizer)\n",
        "        self.bias_regularizer = regularizers.get(bias_regularizer)\n",
        "        self.activity_regularizer = regularizers.get(activity_regularizer)\n",
        "        self.kernel_constraint = constraints.get(kernel_constraint)\n",
        "        self.bias_constraint = constraints.get(bias_constraint)\n",
        "\n",
        "        self.dropout = dropout\n",
        "        self.supports_masking = True\n",
        "        self.input_spec = [InputSpec(ndim=3)]\n",
        "        self.input_dim = input_dim\n",
        "        self.input_length = input_length\n",
        "        if self.input_dim:\n",
        "            kwargs['input_shape'] = (self.input_length, self.input_dim)\n",
        "        super(QRNN, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        if isinstance(input_shape, list):\n",
        "            input_shape = input_shape[0]\n",
        "\n",
        "        batch_size = input_shape[0] if self.stateful else None\n",
        "        self.input_dim = input_shape[2]\n",
        "        self.input_spec = InputSpec(shape=(batch_size, None, self.input_dim))\n",
        "        self.state_spec = InputSpec(shape=(batch_size, self.units))\n",
        "\n",
        "        self.states = [None]\n",
        "        if self.stateful:\n",
        "            self.reset_states()\n",
        "\n",
        "        kernel_shape = (self.window_size, 1, self.input_dim, self.units * 3)\n",
        "        self.kernel = self.add_weight(name='kernel',\n",
        "                                      shape=kernel_shape,\n",
        "                                      initializer=self.kernel_initializer,\n",
        "                                      regularizer=self.kernel_regularizer,\n",
        "                                      constraint=self.kernel_constraint)\n",
        "        if self.use_bias:\n",
        "            self.bias = self.add_weight(name='bias', \n",
        "                                        shape=(self.units * 3,),\n",
        "                                        initializer=self.bias_initializer,\n",
        "                                        regularizer=self.bias_regularizer,\n",
        "                                        constraint=self.bias_constraint)\n",
        "\n",
        "        self.built = True\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        if isinstance(input_shape, list):\n",
        "            input_shape = input_shape[0]\n",
        "\n",
        "        length = input_shape[1]\n",
        "        if length:\n",
        "            length = conv_output_length(length + self.window_size - 1,\n",
        "                                        self.window_size, 'valid',\n",
        "                                        self.strides[0])\n",
        "        if self.return_sequences:\n",
        "            return (input_shape[0], length, self.units)\n",
        "        else:\n",
        "            return (input_shape[0], self.units)\n",
        "\n",
        "    def compute_mask(self, inputs, mask):\n",
        "        if self.return_sequences:\n",
        "            return mask\n",
        "        else:\n",
        "            return None\n",
        "\n",
        "    def get_initial_states(self, inputs):\n",
        "        # build an all-zero tensor of shape (samples, units)\n",
        "        initial_state = K.zeros_like(inputs)  # (samples, timesteps, input_dim)\n",
        "        initial_state = K.sum(initial_state, axis=(1, 2))  # (samples,)\n",
        "        initial_state = K.expand_dims(initial_state)  # (samples, 1)\n",
        "        initial_state = K.tile(initial_state, [1, self.units])  # (samples, units)\n",
        "        initial_states = [initial_state for _ in range(len(self.states))]\n",
        "        return initial_states\n",
        "\n",
        "    def reset_states(self, states=None):\n",
        "        if not self.stateful:\n",
        "            raise AttributeError('Layer must be stateful.')\n",
        "        if not self.input_spec:\n",
        "            raise RuntimeError('Layer has never been called '\n",
        "                               'and thus has no states.')\n",
        "\n",
        "        batch_size = self.input_spec.shape[0]\n",
        "        if not batch_size:\n",
        "            raise ValueError('If a QRNN is stateful, it needs to know '\n",
        "                             'its batch size. Specify the batch size '\n",
        "                             'of your input tensors: \\n'\n",
        "                             '- If using a Sequential model, '\n",
        "                             'specify the batch size by passing '\n",
        "                             'a `batch_input_shape` '\n",
        "                             'argument to your first layer.\\n'\n",
        "                             '- If using the functional API, specify '\n",
        "                             'the time dimension by passing a '\n",
        "                             '`batch_shape` argument to your Input layer.')\n",
        "\n",
        "        if self.states[0] is None:\n",
        "            self.states = [K.zeros((batch_size, self.units))\n",
        "                           for _ in self.states]\n",
        "        elif states is None:\n",
        "            for state in self.states:\n",
        "                K.set_value(state, np.zeros((batch_size, self.units)))\n",
        "        else:\n",
        "            if not isinstance(states, (list, tuple)):\n",
        "                states = [states]\n",
        "            if len(states) != len(self.states):\n",
        "                raise ValueError('Layer ' + self.name + ' expects ' +\n",
        "                                 str(len(self.states)) + ' states, '\n",
        "                                 'but it received ' + str(len(states)) +\n",
        "                                 'state values. Input received: ' +\n",
        "                                 str(states))\n",
        "            for index, (value, state) in enumerate(zip(states, self.states)):\n",
        "                if value.shape != (batch_size, self.units):\n",
        "                    raise ValueError('State ' + str(index) +\n",
        "                                     ' is incompatible with layer ' +\n",
        "                                     self.name + ': expected shape=' +\n",
        "                                     str((batch_size, self.units)) +\n",
        "                                     ', found shape=' + str(value.shape))\n",
        "                K.set_value(state, value)\n",
        "\n",
        "    def __call__(self, inputs, initial_state=None, **kwargs):\n",
        "        # If `initial_state` is specified,\n",
        "        # and if it a Keras tensor,\n",
        "        # then add it to the inputs and temporarily\n",
        "        # modify the input spec to include the state.\n",
        "        if initial_state is not None:\n",
        "            if hasattr(initial_state, '_keras_history'):\n",
        "                # Compute the full input spec, including state\n",
        "                input_spec = self.input_spec\n",
        "                state_spec = self.state_spec\n",
        "                if not isinstance(state_spec, list):\n",
        "                    state_spec = [state_spec]\n",
        "                self.input_spec = [input_spec] + state_spec\n",
        "\n",
        "                # Compute the full inputs, including state\n",
        "                if not isinstance(initial_state, (list, tuple)):\n",
        "                    initial_state = [initial_state]\n",
        "                inputs = [inputs] + list(initial_state)\n",
        "\n",
        "                # Perform the call\n",
        "                output = super(QRNN, self).__call__(inputs, **kwargs)\n",
        "\n",
        "                # Restore original input spec\n",
        "                self.input_spec = input_spec\n",
        "                return output\n",
        "            else:\n",
        "                kwargs['initial_state'] = initial_state\n",
        "        return super(QRNN, self).__call__(inputs, **kwargs)\n",
        "\n",
        "    def call(self, inputs, mask=None, initial_state=None, training=None):\n",
        "        # input shape: `(samples, time (padded with zeros), input_dim)`\n",
        "        # note that the .build() method of subclasses MUST define\n",
        "        # self.input_spec and self.state_spec with complete input shapes.\n",
        "        if isinstance(inputs, list):\n",
        "            initial_states = inputs[1:]\n",
        "            inputs = inputs[0]\n",
        "        elif initial_state is not None:\n",
        "            pass\n",
        "        elif self.stateful:\n",
        "            initial_states = self.states\n",
        "        else:\n",
        "            initial_states = self.get_initial_states(inputs)\n",
        "\n",
        "        if len(initial_states) != len(self.states):\n",
        "            raise ValueError('Layer has ' + str(len(self.states)) +\n",
        "                             ' states but was passed ' +\n",
        "                             str(len(initial_states)) +\n",
        "                             ' initial states.')\n",
        "        input_shape = K.int_shape(inputs)\n",
        "        if self.unroll and input_shape[1] is None:\n",
        "            raise ValueError('Cannot unroll a RNN if the '\n",
        "                             'time dimension is undefined. \\n'\n",
        "                             '- If using a Sequential model, '\n",
        "                             'specify the time dimension by passing '\n",
        "                             'an `input_shape` or `batch_input_shape` '\n",
        "                             'argument to your first layer. If your '\n",
        "                             'first layer is an Embedding, you can '\n",
        "                             'also use the `input_length` argument.\\n'\n",
        "                             '- If using the functional API, specify '\n",
        "                             'the time dimension by passing a `shape` '\n",
        "                             'or `batch_shape` argument to your Input layer.')\n",
        "        constants = self.get_constants(inputs, training=None)\n",
        "        preprocessed_input = self.preprocess_input(inputs, training=None)\n",
        "\n",
        "        last_output, outputs, states = K.rnn(self.step, preprocessed_input,\n",
        "                                            initial_states,\n",
        "                                            go_backwards=self.go_backwards,\n",
        "                                            mask=mask,\n",
        "                                            constants=constants,\n",
        "                                            unroll=self.unroll,\n",
        "                                            input_length=input_shape[1])\n",
        "        if self.stateful:\n",
        "            updates = []\n",
        "            for i in range(len(states)):\n",
        "                updates.append((self.states[i], states[i]))\n",
        "            self.add_update(updates, inputs)\n",
        "\n",
        "        # Properly set learning phase\n",
        "        if 0 < self.dropout < 1:\n",
        "            last_output._uses_learning_phase = True\n",
        "            outputs._uses_learning_phase = True\n",
        "\n",
        "        if self.return_sequences:\n",
        "            return outputs\n",
        "        else:\n",
        "            return last_output\n",
        "\n",
        "    def preprocess_input(self, inputs, training=None):\n",
        "        if self.window_size > 1:\n",
        "            inputs = K.temporal_padding(inputs, (self.window_size-1, 0))\n",
        "        inputs = K.expand_dims(inputs, 2)  # add a dummy dimension\n",
        "\n",
        "        output = K.conv2d(inputs, self.kernel, strides=self.strides,\n",
        "                          padding='valid',\n",
        "                          data_format='channels_last')\n",
        "        output = K.squeeze(output, 2)  # remove the dummy dimension\n",
        "        if self.use_bias:\n",
        "            output = K.bias_add(output, self.bias, data_format='channels_last')\n",
        "\n",
        "        if self.dropout is not None and 0. < self.dropout < 1.:\n",
        "            z = output[:, :, :self.units]\n",
        "            f = output[:, :, self.units:2 * self.units]\n",
        "            o = output[:, :, 2 * self.units:]\n",
        "            f = K.in_train_phase(1 - _dropout(1 - f, self.dropout), f, training=training)\n",
        "            return K.concatenate([z, f, o], -1)\n",
        "        else:\n",
        "            return output\n",
        "\n",
        "    def step(self, inputs, states):\n",
        "        prev_output = states[0]\n",
        "\n",
        "        z = inputs[:, :self.units]\n",
        "        f = inputs[:, self.units:2 * self.units]\n",
        "        o = inputs[:, 2 * self.units:]\n",
        "\n",
        "        z = self.activation(z)\n",
        "        f = f if self.dropout is not None and 0. < self.dropout < 1. else K.sigmoid(f)\n",
        "        o = K.sigmoid(o)\n",
        "\n",
        "        output = f * prev_output + (1 - f) * z\n",
        "        output = o * output\n",
        "\n",
        "        return output, [output]\n",
        "\n",
        "    def get_constants(self, inputs, training=None):\n",
        "        return []\n",
        " \n",
        "    def get_config(self):\n",
        "        config = {'units': self.units,\n",
        "                  'window_size': self.window_size,\n",
        "                  'stride': self.strides[0],\n",
        "                  'return_sequences': self.return_sequences,\n",
        "                  'go_backwards': self.go_backwards,\n",
        "                  'stateful': self.stateful,\n",
        "                  'unroll': self.unroll,\n",
        "                  'use_bias': self.use_bias,\n",
        "                  'dropout': self.dropout,\n",
        "                  'activation': activations.serialize(self.activation),\n",
        "                  'kernel_initializer': initializers.serialize(self.kernel_initializer),\n",
        "                  'bias_initializer': initializers.serialize(self.bias_initializer),\n",
        "                  'kernel_regularizer': regularizers.serialize(self.kernel_regularizer),\n",
        "                  'bias_regularizer': regularizers.serialize(self.bias_regularizer),\n",
        "                  'activity_regularizer': regularizers.serialize(self.activity_regularizer),\n",
        "                  'kernel_constraint': constraints.serialize(self.kernel_constraint),\n",
        "                  'bias_constraint': constraints.serialize(self.bias_constraint),\n",
        "                  'input_dim': self.input_dim,\n",
        "                  'input_length': self.input_length}\n",
        "        base_config = super(QRNN, self).get_config()\n",
        "        return dict(list(base_config.items()) + list(config.items()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5UjHrG4sVrCu"
      },
      "outputs": [],
      "source": [
        "def create_model(transformer,conv_units=128,qrnn_units=256,dense_units=64):\n",
        "    input_ids= tf.keras.layers.Input(shape=(256,), dtype='int32')\n",
        "    input_masks = tf.keras.layers.Input(shape=(256,), dtype='int32')\n",
        "    embedding_layer=transformer(input_ids, attention_mask=input_masks)[0]\n",
        "\n",
        "    OFF = tf.keras.layers.Conv1D(conv_units, kernel_size = 3, padding = \"valid\", kernel_initializer = \"glorot_uniform\")(embedding_layer)\n",
        "    OFF_f = QRNN(qrnn_units)(OFF)  \n",
        "    OFF_b = QRNN(qrnn_units, go_backwards=True)(OFF)\n",
        "    OFF = tf.keras.layers.concatenate([OFF_f, OFF_b])\n",
        "    OFF =tf.keras.layers.Dropout(0.3,seed=52)(OFF)\n",
        "    output_OFF=tf.keras.layers.Dense(1, activation=\"sigmoid\",name=\"output_OFF\")(OFF)\n",
        "    \n",
        "    HS = tf.keras.layers.Conv1D(conv_units, kernel_size = 3, padding = \"valid\", kernel_initializer = \"glorot_uniform\")(embedding_layer)\n",
        "    HS_f = QRNN(qrnn_units)(HS)  \n",
        "    HS_b = QRNN(qrnn_units, go_backwards=True)(HS)\n",
        "    HS = tf.keras.layers.concatenate([HS_f, HS_b])\n",
        "    HS =tf.keras.layers.Dropout(0.3,seed=52)(HS)    \n",
        "    output_HS=tf.keras.layers.Dense(7, activation=\"softmax\",name=\"output_HS\")(HS)\n",
        "\n",
        "    model = tf.keras.Model(inputs=[input_ids, input_masks], outputs = [output_OFF,output_HS])\n",
        "    \n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MvnYJPLHvQNb"
      },
      "outputs": [],
      "source": [
        "def build_model():\n",
        "    with tpu_strategy.scope():\n",
        "        config =AutoConfig.from_pretrained(\"UBC-NLP/MARBERTv2\",dropout=0.3,seed=3,attention_dropout=0.3,output_hidden_states = True)\n",
        "        transformer= TFAutoModel.from_pretrained(\"UBC-NLP/MARBERTv2\",config=config)\n",
        "        return create_model(transformer)\n",
        "\n",
        "model=build_model()\n",
        "\n",
        "def train_model(model,input_ids,input_masks,label_OFF,label_HS,batch_size=32,epochs_frozen=4,epochs_unfrozen=16,verbose=1):\n",
        "   \n",
        "    if epochs_frozen:\n",
        "        \n",
        "        for layer in model.layers[:3]:\n",
        "            layer.trainable = False\n",
        "\n",
        "        with tpu_strategy.scope():\n",
        "            model.compile(loss={\"output_OFF\":\"binary_crossentropy\",\"output_HS\":\"sparse_categorical_crossentropy\"},\n",
        "                          optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3), \n",
        "                          metrics={\"output_OFF\":\"accuracy\",\"output_HS\":\"sparse_categorical_accuracy\"}\n",
        "                          #loss_weights={\"output_OFF\":1,\"output_HS\":1.5}\n",
        "                         )\n",
        "\n",
        "            model.fit([input_ids, input_masks],[label_OFF,label_HS],batch_size=64,epochs=epochs_frozen,verbose=verbose,\n",
        "                   validation_data=([valid_input_ids,valid_input_masks], [valid_OFF,valid_HS]))\n",
        "        \n",
        "    if epochs_unfrozen:\n",
        "        \n",
        "        for layer in model.layers[:3]:\n",
        "            layer.trainable = True\n",
        "\n",
        "        with tpu_strategy.scope():\n",
        "            model.compile(loss={\"output_OFF\":\"binary_crossentropy\",\"output_HS\":\"sparse_categorical_crossentropy\"},\n",
        "                          optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4), \n",
        "                          metrics={\"output_OFF\":\"accuracy\",\"output_HS\":\"sparse_categorical_accuracy\"}\n",
        "                          #loss_weights={\"output_OFF\":1,\"output_HS\":1.5}\n",
        "                         )\n",
        "\n",
        "            model.fit([input_ids, input_masks],[label_OFF,label_HS],batch_size=64,epochs=epochs_unfrozen,verbose=verbose,\n",
        "                    validation_data=([valid_input_ids,valid_input_masks], [valid_OFF,valid_HS]))\n",
        "\n",
        "train_model(model,train_input_ids,train_input_masks,train_OFF,train_HS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n4kLuN65vQNc"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model,input_ids,input_masks,labels_OFF,labels_HS,labels_OFF_not_HS,labels_HS_bn):\n",
        "    predictions_OFF,predictions_HS=model.predict([input_ids,input_masks])\n",
        "    print(f\"TaskA:{eval_taskA(predictions_OFF,labels_OFF)}\")\n",
        "    print(f\"TaskB:{eval_taskB(predictions_HS,labels_HS_bn)}\")\n",
        "    print(f\"TaskC:{eval_taskC(predictions_HS,labels_HS)}\")\n",
        "evaluate_model(model,valid_input_ids,valid_input_masks,valid_OFF,valid_HS,valid_OFF_not_HS,valid_HS_bn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cr79rZrWIkm4"
      },
      "outputs": [],
      "source": [
        "evaluate_model(model,train_input_ids,train_input_masks,train_OFF,train_HS,train_OFF_not_HS,train_HS_bn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xUidRB8UvQNc",
        "tags": []
      },
      "outputs": [],
      "source": [
        "def zip_file(task):\n",
        "    with ZipFile(task+\".zip\", 'w') as myzip:\n",
        "        myzip.write(task+\".txt\")\n",
        "    myzip.close()\n",
        "    \n",
        "def submission_gen_taskA(predictions):\n",
        "    sub=[]\n",
        "    for i in predictions:\n",
        "        if i==1:\n",
        "            sub.append(\"OFF\")\n",
        "        else :\n",
        "            sub.append(\"NOT_OFF\")\n",
        "    pd.DataFrame(sub).to_csv(\"TaskA.txt\",index=False,header=False)\n",
        "\n",
        "def submission_gen_taskB(predictions):\n",
        "    sub=[]\n",
        "    for i in predictions:\n",
        "        if i==1:\n",
        "            sub.append(\"HS\")\n",
        "        else :\n",
        "            sub.append(\"NOT_HS\")\n",
        "    pd.DataFrame(sub).to_csv(\"LB.txt\",index=False,header=False)\n",
        "\n",
        "def submission_gen_taskC(predictions):\n",
        "    sub=[]\n",
        "    for i in predictions:\n",
        "        if i==0:\n",
        "            sub.append(\"NOT_HS\")\n",
        "        else:\n",
        "            sub.append(\"HS\"+str(i))\n",
        "    pd.DataFrame(sub).to_csv(\"LC.txt\",index=False,header=False)\n",
        "    \n",
        "def submission_gen():\n",
        "    submission_gen_taskA(eval_taskA(ta,valid_OFF,return_predictions=True))\n",
        "    submission_gen_taskB(eval_taskB2(tc,valid_HS,return_predictions=True))\n",
        "    submission_gen_taskC(eval_taskC(valid_OFF,valid_HS_bn,return_predictions=True))\n",
        "\n",
        "#submission_gen()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yYa1HE_C8smL"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}